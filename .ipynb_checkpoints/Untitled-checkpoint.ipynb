{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18423d3a",
   "metadata": {},
   "source": [
    "### import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc166cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import re\n",
    "import tqdm \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from nltk import ngrams\n",
    "import seaborn as sns\n",
    "import matplotlib as mpl\n",
    "import matplotlib.font_manager as fm\n",
    "from collections import Counter\n",
    "import sentencepiece as spm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdafebfd",
   "metadata": {},
   "source": [
    "### import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46c659cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.getenv('HOME') +'/PocLab/Model'\n",
    "spm_4000 = spm.SentencePieceProcessor()\n",
    "spm_4000.Load(data_path + '/spm_dec_v.model')\n",
    "\n",
    "\n",
    "data_path = os.getenv('HOME') +'/PocLab/Preprocessing'\n",
    "spm_8000 = spm.SentencePieceProcessor()\n",
    "spm_8000.Load(data_path + '/spm_dec_8009.model')\n",
    "\n",
    "msp_4000 = spm.SentencePieceProcessor()\n",
    "msp_4000.Load(data_path + '/spm_dec_mecab_4009.model')\n",
    "\n",
    "msp_8000 = spm.SentencePieceProcessor()\n",
    "msp_8000.Load(data_path + '/spm_dec_msp8009.model')\n",
    "\n",
    "custom_msp_4000 = spm.SentencePieceProcessor()\n",
    "custom_msp_4000.Load(data_path + '/spm_dec_custom_msp4009.model')\n",
    "\n",
    "custom_msp_8000 =  spm.SentencePieceProcessor()\n",
    "custom_msp_8000.Load(data_path + '/spm_dec_custom_msp8009.model')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a9035a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 토크나이저 dict 만들기\n",
    "\n",
    "tokenizers_4000 = {'spm' : spm_4000, 'msp' : msp_4000, 'custom_msp' : custom_msp_4000}\n",
    "tokenizers_8000 = {'spm' : spm_8000, 'msp' : msp_8000, 'custom_msp' : custom_msp_8000}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "211661b7",
   "metadata": {},
   "source": [
    "### unk count\n",
    "- OOV 개수 확인"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59cd5fe3",
   "metadata": {},
   "source": [
    "#### 4000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd936a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_spm= []\n",
    "tok_msp= []\n",
    "tok_coustom = []\n",
    "split_token = set()\n",
    "dial = df_train['dial'].values\n",
    "for i in tqdm.tqdm(dial) :\n",
    "    split_token |= set(i.split())\n",
    "    tok_spm.extend(spm_4000.encode(i))\n",
    "    tok_msp.extend(msp_4000.encode(i))\n",
    "    tok_coustom.extend(custom_msp_4000.encode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9fa951",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('split unk cnt : ', 4000 -  len(split_token)*-1)\n",
    "print('spm unk cnt : ', tok_spm.count(spm_4000.unk_id()))\n",
    "print('msp unk cnt : ', tok_msp.count(msp_4000.unk_id()))\n",
    "print('custom_msp unk cnt : ', tok_coustom.count(custom_msp_4000.unk_id()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef4a186",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar = ax.bar(x=['split','spm','msp','custom'], height = [752112,tok_spm.count(spm_4000.unk_id()),tok_msp.count(spm_4000.unk_id()),custom_msp_4000.unk_id())])\n",
    "ax.bar_label(bar,fontsize=12)\n",
    "sns.despine()\n",
    "plt.title('4000_data : Unknown token count by tokenizer')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55e5601",
   "metadata": {},
   "source": [
    "#### 8000\n",
    "- msp_8000data는 없음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71b95c12",
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_spm= []\n",
    "tok_msp= []\n",
    "tok_coustom = []\n",
    "split_token = set()\n",
    "dial = df_train['dial'].values\n",
    "for i in tqdm.tqdm(dial) :\n",
    "    split_token |= set(i.split())\n",
    "    tok_spm.extend(spm_8000.encode(i))\n",
    "    tok_msp.extend(msp_8000.encode(i))\n",
    "    tok_coustom.extend(custom_msp_8000.encode(i))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61b46698",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('split unk cnt : ', 8000 -  len(split_token)*-1)\n",
    "print('spm unk cnt : ', tok_spm.count(spm_8000.unk_id()))\n",
    "print('msp unk cnt : ', tok_msp.count(msp_8000.unk_id()))\n",
    "print('custom_msp unk cnt : ', tok_coustom.count(custom_msp_8000.unk_id()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49231fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar = ax.bar(x=['split','spm','msp','custom'], height = [752112,tok_spm.count(spm_8000.unk_id()),msp_8000.unk_id()),custom_msp_8000.unk_id())])\n",
    "ax.bar_label(bar,fontsize=12)\n",
    "sns.despine()\n",
    "plt.title('8000_data : Unknown token count by tokenizer')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696d4610",
   "metadata": {},
   "source": [
    "### subword fertility\n",
    "- 토큰화된 단어마다 생성되는 부분단어의 평균 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbd8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000_data\n",
    "\n",
    "tok_spm= []\n",
    "tok_msp= []\n",
    "tok_custom= []\n",
    "dial = df_train['dial'].values\n",
    "for i in tqdm.tqdm(dial) :\n",
    "    #split by empty space\n",
    "    tok_spm_len_split = len(i.split())\n",
    "    \n",
    "    #split by tokenzier\n",
    "    tok_spm_len = len(spm_4000.encode(i))\n",
    "    tok_msp_len = len(msp_4000.encode(i))\n",
    "    tok_custom_len = len(custom_msp_4000.encode(i))\n",
    "    \n",
    "    # find percentage of subword split\n",
    "    tok_spm.append(tok_spm_len / tok_spm_len_split )\n",
    "    tok_msp.append(tok_msp_len / tok_spm_len_split)\n",
    "    tok_custom.append(tok_custom_len / tok_spm_len_split)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a31b819",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('spm subword fertility :',sum(tok_spm)/len(tok_spm))\n",
    "print('msp subword fertility :',sum(tok_msp)/len(tok_msp))\n",
    "print('custom_msp subword fertility :',sum(tok_custom)/len(tok_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "601f8d19",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar = ax.bar(x=['spm','msp'], height = [round(sum(tok_spm)/len(tok_spm),2),round(sum(tok_msp)/len(tok_msp),2),round(sum(tok_custom)/len(tok_custom),2)])\n",
    "ax.bar_label(bar,fontsize=12)\n",
    "sns.despine()\n",
    "plt.title('4000_data subword fertility by tokenizer')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e29ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8000_data\n",
    "\n",
    "tok_spm= []\n",
    "# tok_msp= []\n",
    "tok_custom= []\n",
    "dial = df_train['dial'].values\n",
    "for i in tqdm.tqdm(dial) :\n",
    "    #split by empty space\n",
    "    tok_spm_len_split = len(i.split())\n",
    "    \n",
    "    #split by tokenzier\n",
    "    tok_spm_len = len(spm_8000.encode(i))\n",
    "#     tok_msp_len = len(msp_8000.encode(i))\n",
    "    tok_custom_len = len(custom_msp_8000.encode(i))\n",
    "    \n",
    "    # find percentage of subword split\n",
    "    tok_spm.append(tok_spm_len / tok_spm_len_split )\n",
    "#     tok_msp.append(tok_msp_len / tok_spm_len_split)\n",
    "    tok_custom.append(tok_custom_len / tok_spm_len_split)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c196d1b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('spm subword fertility :',sum(tok_spm)/len(tok_spm))\n",
    "# print('msp subword fertility :',sum(tok_msp)/len(tok_msp))\n",
    "print('custom_msp subword fertility :',sum(tok_custom)/len(tok_custom))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54655a1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar = ax.bar(x=['spm','msp'], height = [round(sum(tok_spm)/len(tok_spm),2),round(sum(tok_custom)/len(tok_custom),2)])\n",
    "ax.bar_label(bar,fontsize=12)\n",
    "sns.despine()\n",
    "plt.title('8000_data subword fertility by tokenizer')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48a4b394",
   "metadata": {},
   "source": [
    "### proportion of continued words\n",
    "- 말뭉치에서 적어도 두 개의 부분 토큰으로 분할된 토큰화된 단어의 비율 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1461b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4000_data\n",
    "\n",
    "tok_spm= []\n",
    "tok_msp= []\n",
    "tok_split = []\n",
    "tok_custom= []\n",
    "dial = df_train['dial'].values\n",
    "for i in tqdm.tqdm(dial) :\n",
    "    total_cnt = 0\n",
    "    spm_temp = 0\n",
    "    msp_temp = 0\n",
    "    custom_temp = 0    \n",
    "    for k in i.split() :\n",
    "        if k == ' ' or k ==  '\\u200b' or k =='\\x9f':\n",
    "            continue\n",
    "        total_cnt += 1\n",
    "        word_spm = spm_4000.encode_as_pieces(k)\n",
    "        word_msp = msp_4000.encode_as_pieces(k)\n",
    "        word_custom = custom_msp_4000.encode_as_pieces(k)        \n",
    "        \n",
    "        if word_spm[0] == '▁' :\n",
    "            word_spm.remove('▁')\n",
    "            \n",
    "        if word_msp[0] == '▁' :\n",
    "            word_msp.remove('▁')\n",
    "            \n",
    "        if word_custom[0] == '▁' :\n",
    "            word_custom.remove('▁')\n",
    "            \n",
    "        if len(word_spm) > 1 : spm_temp+=1\n",
    "        if len(word_msp) > 1 : msp_temp+=1\n",
    "        if len(word_custom) > 1 : msp_temp+=1            \n",
    "                        \n",
    "    tok_spm.append(spm_temp)\n",
    "    tok_msp.append(msp_temp)\n",
    "    tok_split.append(total_cnt)\n",
    "    tok_custom.append(custom_temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "affd676f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('spm proportion of continued words :',sum(tok_spm)/sum(tok_split) * 100)\n",
    "print('msp proportion of continued words :',sum(tok_msp)/sum(tok_split) * 100)\n",
    "print('custom_msp proportion of continued words :',sum(tok_custom)/sum(tok_split) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf86c06",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar = ax.bar(x=['spm','msp','custom_msp'], height = [round(sum(tok_spm)/sum(tok_split) * 100,2),round(sum(tok_msp)/sum(tok_split) * 100,2),round(sum(tok_custom)/sum(tok_split) * 100,2)])\n",
    "ax.bar_label(bar,fontsize=12)\n",
    "sns.despine()\n",
    "plt.title('4000_data : proportion of continued words by tokenizer')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca3fd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8000_data\n",
    "\n",
    "tok_spm= []\n",
    "tok_msp= []\n",
    "tok_split = []\n",
    "tok_custom= []\n",
    "dial = df_train['dial'].values\n",
    "for i in tqdm.tqdm(dial) :\n",
    "    total_cnt = 0\n",
    "    spm_temp = 0\n",
    "    msp_temp = 0\n",
    "    custom_temp = 0    \n",
    "    for k in i.split() :\n",
    "        if k == ' ' or k ==  '\\u200b' or k =='\\x9f':\n",
    "            continue\n",
    "        total_cnt += 1\n",
    "        word_spm = spm_8000.encode_as_pieces(k)\n",
    "#         word_msp = msp_4000.encode_as_pieces(k)\n",
    "        word_custom = custom_msp_8000.encode_as_pieces(k)        \n",
    "        \n",
    "        if word_spm[0] == '▁' :\n",
    "            word_spm.remove('▁')\n",
    "            \n",
    "        if word_msp[0] == '▁' :\n",
    "            word_msp.remove('▁')\n",
    "            \n",
    "        if word_custom[0] == '▁' :\n",
    "            word_custom.remove('▁')\n",
    "            \n",
    "        if len(word_spm) > 1 : spm_temp+=1\n",
    "        if len(word_msp) > 1 : msp_temp+=1\n",
    "        if len(word_custom) > 1 : msp_temp+=1            \n",
    "                        \n",
    "    tok_spm.append(spm_temp)\n",
    "    tok_msp.append(msp_temp)\n",
    "    tok_split.append(total_cnt)\n",
    "    tok_custom.append(custom_temp)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872fa515",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('spm proportion of continued words :',sum(tok_spm)/sum(tok_split) * 100)\n",
    "print('msp proportion of continued words :',sum(tok_msp)/sum(tok_split) * 100)\n",
    "print('custom_msp proportion of continued words :',sum(tok_custom)/sum(tok_split) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fe60f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "bar = ax.bar(x=['spm','msp','custom_msp'], height = [round(sum(tok_spm)/sum(tok_split) * 100,2),round(sum(tok_msp)/sum(tok_split) * 100,2),round(sum(tok_custom)/sum(tok_split) * 100,2)])\n",
    "ax.bar_label(bar,fontsize=12)\n",
    "sns.despine()\n",
    "plt.title('8000_data : proportion of continued words by tokenizer')\n",
    "plt.yticks(fontsize=10)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
